{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate words for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/89/qp8kb90s49z7xcdskq2c0qlm0000gn/T/jieba.cache\n",
      "Loading model cost 0.872 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "\n",
    "# 创建停用词list\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "# 对句子进行分词\n",
    "def seg_sentence(sentence):\n",
    "    sentence_seged = jieba.cut(sentence.strip())\n",
    "    stopwords = stopwordslist('stoped.txt')  # 这里加载停用词的路径\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr\n",
    "\n",
    "inputs = open('哈利波特与魔法石(人文版).txt', 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "outputs = open('output.txt', 'w') #加载处理后的文件路径\n",
    "for line in inputs:\n",
    "    line_seg = seg_sentence(line)  # 这里的返回值是字符串\n",
    "    outputs.write(line_seg)\n",
    "outputs.close()\n",
    "inputs.close()\n",
    "# WordCount\n",
    "with open('output.txt', 'r') as fr: #读入已经去除停用词的文件\n",
    "    data = jieba.cut(fr.read())\n",
    "data = dict(Counter(data))\n",
    "\n",
    "with open('cipin.txt', 'w') as fw: #读入存储wordcount的文件路径\n",
    "    for k, v in data.items():\n",
    "        fw.write('%s,%d\\n' % (k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分句子\n",
    "# 版本为python3，如果为python2需要在字符串前面加上u\n",
    "import re\n",
    "def cut_sent(para):\n",
    "    para = re.sub('([。！？\\?])([^”’])', r\"\\1\\n\\2\", para)  # 单字符断句符\n",
    "    para = re.sub('([，！？\\?])([^”’])', r\"\\1\\n\\2\", para)  # 单字符断句符\n",
    "    para = re.sub('(\\.{6})([^”’])', r\"\\1\\n\\2\", para)  # 英文省略号\n",
    "    para = re.sub('(\\…{2})([^”’])', r\"\\1\\n\\2\", para)  # 中文省略号\n",
    "    para = re.sub('([。！？\\?][”’])([^，。！？\\?])', r'\\1\\n\\2', para)\n",
    "    \n",
    "    # 如果双引号前有终止符，那么双引号才是句子的终点，把分句符\\n放到双引号后，注意前面的几句都小心保留了双引号\n",
    "    para = para.rstrip()  # 段尾如果有多余的\\n就去掉它\n",
    "    # 很多规则中会考虑分号;，但是这里我把它忽略不计，破折号、英文双引号等同样忽略，需要的再做些简单调整即可。\n",
    "    return para.split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the length of the sentenct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_sentence_len=dict()\n",
    "inputs = open('哈利波特与魔法石(人文版).txt', 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "for line in inputs:\n",
    "    l=cut_sent(line)\n",
    "    for w in l:\n",
    "        line_seg = seg_sentence(w) \n",
    "        words=list(line_seg.split(' '))\n",
    "        dict_sentence_len[line_seg]=len(words)-1\n",
    "        #print(words)\n",
    "        #print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dict into dataframe and save the results of sentence-length into .xls file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_len=pd.DataFrame(columns = ['句子','长度'])\n",
    "df_sentence_len.head()\n",
    "df_sentence_len['句子']=dict_sentence_len.keys()\n",
    "df_sentence_len['长度']=dict_sentence_len.values()\n",
    "df_sentence_len.to_excel('句子长度.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read character file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>邓布利多</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>亚瑟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>韦斯莱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>巴特缪斯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>巴蒂</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character\n",
       "0      邓布利多\n",
       "1        亚瑟\n",
       "2       韦斯莱\n",
       "3      巴特缪斯\n",
       "4        巴蒂"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('哈利波特与魔法石(人文版).txt', 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "roles_df=pd.read_excel('character.xlsx',names=['character'],index=[0])\n",
    "roles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the frequency of roles in certain length text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roles(inputs):\n",
    "    roles_dict=dict()\n",
    "    \n",
    "    for line in inputs:\n",
    "        line_seg = seg_sentence(line)\n",
    "        words_list=list(line_seg.split(' '))\n",
    "        #print(words_list)\n",
    "        for role in roles_df['character']:\n",
    "            #print(role)\n",
    "            if role in words_list:\n",
    "                if role not in roles_dict:\n",
    "                    roles_dict[role]=1\n",
    "                else:\n",
    "                    roles_dict[role]+=1\n",
    "                #print(role)\n",
    "    return roles_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate roles of the whole text\n",
    "#calculate_roles(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第2章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>第3章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>第4章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>第5章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第6章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chapter             \n",
       "0     第2章 NaN NaN  NaN\n",
       "1     第3章 NaN NaN  NaN\n",
       "2     第4章 NaN NaN  NaN\n",
       "3     第5章 NaN NaN  NaN\n",
       "4     第6章 NaN NaN  NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('哈利波特与魔法石(人文版).txt', 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "chapter_df=pd.read_excel('chapters.xlsx',names=['chapter','','',''],index=[0])\n",
    "chapter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seperate chapters and save all chapters into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "one_chapter=list() #used to save all lines in single chapter\n",
    "all_chapters=list() # used to save all chapters into one list\n",
    "for line in text:        # read all lines\n",
    "    if chapter_df['chapter'][i] in line: # identify the chapter mark\n",
    "        #print(chapter_df['chapter'][i])\n",
    "        all_chapters.append(one_chapter) # if true, we save the single chapter into the chapter list\n",
    "        one_chapter=list() # then we initialize the chapter list\n",
    "        i+=1\n",
    "    one_chapter.append(line)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate character frequency in each chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'哈利': 24, '海格': 11, '赫敏': 1, '纳威': 1, '马尔福': 2, '伏地魔': 5, '波特': 18, '闪闪': 1, '邓布利多': 30, '庞弗雷夫人': 1, '小天狼星布莱克': 1}\n",
      "{'哈利': 46}\n",
      "{'哈利': 44, '波特': 2}\n",
      "{'哈利': 38, '海格': 31, '邓布利多': 8, '波特': 8, '伏地魔': 1}\n",
      "{'哈利': 91, '海格': 70, '邓布利多': 4, '波特': 18, '汤姆': 1}\n",
      "{'哈利': 72, '海格': 10, '纳威': 6, '韦斯莱': 5, '伏地魔': 2, '邓布利多': 3, '赫敏': 8, '格兰杰': 3, '德拉科': 2, '马尔福': 14, '高尔': 4, '波特': 4}\n",
      "{'哈利': 41, '海格': 4, '纳威': 6, '赫敏': 5, '皮皮鬼': 5, '格兰杰': 1, '马尔福': 8, '高尔': 1, '波特': 4, '韦斯莱': 5, '邓布利多': 9, '差点没头的尼克': 3, '血人巴罗': 5, '费尔奇': 1}\n",
      "{'哈利': 32, '差点没头的尼克': 1, '皮皮鬼': 2, '费尔奇': 4, '韦斯莱': 3, '宾斯教授': 1, '赫敏': 7, '格兰杰': 2, '海格': 14, '德拉科': 1, '马尔福': 6, '波特': 12, '高尔': 1, '纳威': 3}\n",
      "{'德拉科': 2, '马尔福': 64, '哈利': 62, '纳威': 18, '赫敏': 16, '格兰杰': 5, '海格': 3, '高尔': 4, '韦斯莱': 4, '波特': 14, '邓布利多': 2, '皮皮鬼': 12, '费尔奇': 13, '胖夫人': 5, '庞弗雷夫人': 1, '血人巴罗': 1}\n",
      "{'马尔福': 10, '哈利': 62, '赫敏': 22, '纳威': 3, '高尔': 1, '波特': 6, '韦斯莱': 4, '格兰杰': 8, '邓布利多': 3, '皮皮鬼': 1, '血人巴罗': 1, '胖夫人': 1}\n",
      "{'海格': 16, '哈利': 46, '赫敏': 21, '波特': 8, '费尔奇': 2, '邓布利多': 3, '纳威': 3, '韦斯莱': 6}\n",
      "{'韦斯莱': 11, '海格': 18, '德拉科': 1, '马尔福': 16, '高尔': 2, '哈利': 70, '赫敏': 11, '平斯夫人': 3, '邓布利多': 9, '费尔奇': 7, '胖夫人': 1, '波特': 2}\n",
      "{'邓布利多': 8, '哈利': 44, '费尔奇': 1, '赫敏': 29, '韦斯莱': 9, '纳威': 16, '马尔福': 28, '波特': 8, '高尔': 4, '海格': 1, '庞弗雷夫人': 1, '皮皮鬼': 1}\n",
      "{'哈利': 36, '赫敏': 28, '海格': 31, '邓布利多': 4, '斯普劳特教授': 1, '马尔福': 26, '庞弗雷夫人': 3, '皮皮鬼': 1, '费尔奇': 1}\n",
      "{'费尔奇': 13, '哈利': 63, '赫敏': 24, '纳威': 15, '马尔福': 30, '德拉科': 1, '波特': 12, '格兰杰': 2, '海格': 30, '邓布利多': 3, '伏地魔': 4}\n",
      "{'哈利': 90, '伏地魔': 5, '纳威': 12, '赫敏': 59, '宾斯教授': 1, '韦斯莱': 2, '庞弗雷夫人': 1, '邓布利多': 12, '海格': 12, '波特': 4, '胖夫人': 1, '费尔奇': 3, '皮皮鬼': 6, '血人巴罗': 1, '斯普劳特教授': 1}\n"
     ]
    }
   ],
   "source": [
    "for chaps in all_chapters:  \n",
    "    print(calculate_roles(chaps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'哈利': 90,\n",
       " '伏地魔': 5,\n",
       " '纳威': 12,\n",
       " '赫敏': 59,\n",
       " '宾斯教授': 1,\n",
       " '韦斯莱': 2,\n",
       " '庞弗雷夫人': 1,\n",
       " '邓布利多': 12,\n",
       " '海格': 12,\n",
       " '波特': 4,\n",
       " '胖夫人': 1,\n",
       " '费尔奇': 3,\n",
       " '皮皮鬼': 6,\n",
       " '血人巴罗': 1,\n",
       " '斯普劳特教授': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_roles(chaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_len=pd.DataFrame(columns = ['角色','出现次数'])\n",
    "df_sentence_len.head()\n",
    "df_sentence_len['句子']=dict_sentence_len.keys()\n",
    "df_sentence_len['长度']=dict_sentence_len.values()\n",
    "df_sentence_len.to_excel('句子长度.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第2章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>第3章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>第4章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>第5章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第6章</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chapter             \n",
       "0     第2章 NaN NaN  NaN\n",
       "1     第3章 NaN NaN  NaN\n",
       "2     第4章 NaN NaN  NaN\n",
       "3     第5章 NaN NaN  NaN\n",
       "4     第6章 NaN NaN  NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_df=pd.read_excel('chapters.xlsx',names=['chapter','','',''],index=[0])\n",
    "chapter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
