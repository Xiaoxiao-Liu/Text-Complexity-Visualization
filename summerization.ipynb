{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import codecs\n",
    "import jieba.posseg as pseg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "from pyltp import Segmentor\n",
    "from pyltp import SentenceSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_segmentor = None\n",
    "_sent_splitter = None\n",
    "\n",
    "def split(content):\n",
    "    '''分句和分词'''\n",
    "    global _segmentor, _sent_splitter\n",
    "    if _segmentor is None:\n",
    "        model_path = r'/Users/liuxiaoxiao/pyltp/ltp/ltp_data_v3.4.0/cws.model'\n",
    "        segmentor = Segmentor()  # 初始化实例\n",
    "        segmentor.load(model_path) # 加载分词模型\n",
    "        _segmentor = segmentor  # 设置全局变量, 避免每次都重新加载模型, 耗时\n",
    "        _sent_splitter = SentenceSplitter() # 句子分割模型\n",
    "    sents = _sent_splitter.split(content)  # 先进行分句\n",
    "    _sents = []\n",
    "    for sent in sents:\n",
    "        #print(sent)\n",
    "        words = _segmentor.segment(sent) # 分词\n",
    "        #print(words)\n",
    "        sent = ' '.join(words) # 用空格把词隔开\n",
    "        _sents.append(sent)\n",
    "    content = '. '.join(_sents)  # 用.把句子隔开\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换前: 本模块提供文本摘要的功能。基于TextRank算法来计算文本句子的等级。\n",
      "转换后: 本 模块 提供 文本 摘要 的 功能 。. 基于 TextRank 算法 来 计算 文本 句子 的 等级 。\n"
     ]
    }
   ],
   "source": [
    "content = '本模块提供文本摘要的功能。基于TextRank算法来计算文本句子的等级。'\n",
    "result = split(content)\n",
    "print(f'转换前: {content}')\n",
    "print(f'转换后: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "content = '''\n",
    "使用51篇文章的Opinion数据集进行比较。\n",
    "每篇文章都是关于产品的功能，例如iPod的电池寿命等，并且是购买该产品的客户的评论集合。\n",
    "数据集中的每篇文章都有5个手动编写的“黄金”摘要。\n",
    "通常5金总结是不同的，但它们也可以是相同的文本重复5次。\n",
    "LexRank是这里的赢家，因为它产生了更好的ROUGE和BLEU分数。\n",
    "不幸的是，我们发现由Gensim的TextRank和Luhn模型产生的摘要信息比摘要要少。\n",
    "此外，LexRank并不总是在ROUGE评分中击败TextRank  - 例如，TextRank在DUC 2002数据集上的表现稍好于LexRank。\n",
    "因此，LexRank和TextRank之间的选择取决于您的数据集，值得一试。\n",
    "数据的另一个结论是Gensim的Textrank优于普通的PyTextRank。\n",
    "因为它在明文TextRank中使用BM25函数而不是余弦IDF。\n",
    "表中的另一点是Luhn的算法具有较低的BLEU分数。\n",
    "这是因为它提取了更长的摘要，因此涵盖了更多的产品评论。\n",
    "不幸的是，我们不能缩短它，因为Sumy中Luhn算法的封装不提供参数来改变字数限制。\n",
    "'''\n",
    "#tokens = split(content)\n",
    "#summarize(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '''题目 ：韩娥善歌\n",
    "内容：从前，韩国有位歌唱家名叫韩娥，要到位于东方的齐国去，不想在半路上就断了钱粮，从而使基本生活都发生了困难。为了度过这一难关，她在经过齐国都城西边的雍门时，便用卖唱来换取食物。韩娥唱起歌来，情感是相当投入的，以至在她离开了这个地方以后，她那美妙绝伦的余音还仿佛在城门的梁柱之间缭绕，竟至三日不绝于耳；凡是聆听过韩娥歌唱的人，都还沉浸在她所营造的艺术氛围之中，好像她并没有离开一样。有一天，韩娥来到一家旅店投宿时，店小二狗眼看人，见她穷愁潦倒，便当众羞辱她。韩娥为此伤心至极，禁不住拖着长音痛哭不已。她那哭声弥漫开去，竟使得方圆一里之内的人们，无论男女老幼都为之动容，大家泪眼相向，愁眉不展，人人都难过得三天吃不下饭。后来，韩娥难以安身，便离开了这家旅店。人们发现之后，急急忙忙分头去追赶她，将她请回来，再为劳苦大众纵情高歌一曲。韩娥的热情演唱，又引得一里之内的老人和小孩个个欢呼雀跃，鼓掌助兴，大家忘情地沉浸在欢乐之中，将以往的许多人生悲苦都一扫而光。为了感谢韩娥给他们带来的欢乐，大家送给韩娥许多财物和礼品，使她满载而归。韩娥的故事说明：真正的艺术家，应当扎根于人民大众之中，与大众共悲欢，成为他们忠实的代言人。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'内容 ： 从前 ， 韩国 有 位 歌唱家 名叫 韩娥 ， 要 到 位于 东方 的 齐国 去 ， 不 想 在 半路 上 就 断 了 钱 粮 ， 从而 使 基本 生活 都 发生 了 困难 。.\\n人们 发现 之后 ， 急急忙忙分头 去 追赶 她 ， 将 她 请 回来 ， 再 为 劳苦 大众 纵情 高 歌 一 曲 。.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = split(content)\n",
    "#print(f'转换前: {content}')\n",
    "#print(f'转换后: {result}')\n",
    "summarize(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
