{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import codecs\n",
    "import jieba.posseg as pseg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate words for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/89/qp8kb90s49z7xcdskq2c0qlm0000gn/T/jieba.cache\n",
      "Loading model cost 0.814 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "\n",
    "# 创建停用词list\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "# 对句子进行分词\n",
    "def seg_sentence(sentence):\n",
    "    sentence_seged = jieba.cut(sentence.strip())\n",
    "    stopwords = stopwordslist('stoped.txt')  # 这里加载停用词的路径\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分句子\n",
    "# 版本为python3，如果为python2需要在字符串前面加上u\n",
    "import re\n",
    "def cut_sent(para):\n",
    "    para = re.sub('([。！？\\?])([^”’])', r\"\\1\\n\\2\", para)  # 单字符断句符\n",
    "    para = re.sub('([，！？\\?])([^”’])', r\"\\1\\n\\2\", para)  # 单字符断句符\n",
    "    para = re.sub('(\\.{6})([^”’])', r\"\\1\\n\\2\", para)  # 英文省略号\n",
    "    para = re.sub('(\\…{2})([^”’])', r\"\\1\\n\\2\", para)  # 中文省略号\n",
    "    para = re.sub('([。！？\\?][”’])([^，。！？\\?])', r'\\1\\n\\2', para)\n",
    "    \n",
    "    # 如果双引号前有终止符，那么双引号才是句子的终点，把分句符\\n放到双引号后，注意前面的几句都小心保留了双引号\n",
    "    para = para.rstrip()  # 段尾如果有多余的\\n就去掉它\n",
    "    # 很多规则中会考虑分号;，但是这里我把它忽略不计，破折号、英文双引号等同样忽略，需要的再做些简单调整即可。\n",
    "    return para.split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the length of the sentenct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length(text):\n",
    "    dict_sentence_len=dict()\n",
    "    for line in text: #这个循环是遍历整个文本的，inputs是整个文本，line是文本中的每一段\n",
    "        #print(line)    \n",
    "        l=cut_sent(line)   # l是给一段文本进行拆分句子后的结果\n",
    "        for w in l:  #这个循环是遍历一段文字里的每个句子,l是一段里的所有句子存放的list，w是每个句子\n",
    "            line_seg = seg_sentence(w)  #line_seg 是一个句子拆分词语后的结果\n",
    "            words=list(line_seg.split(' ')) #将一个句子中的词语拆分后逐个存放在list中\n",
    "            dict_sentence_len[line_seg]=len(words)+1  #本句的长度为这个list的长度（+1是因为句子从0开始）\n",
    "    return dict_sentence_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dict into dataframe and save the results of sentence-length into .xls file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read texts\n",
    "\n",
    "# Save the book names in a list\n",
    "file_names=['哈利波特与魔法石','哈利波特与密室','哈利波特与阿兹卡班的囚徒','哈利波特与火焰杯',\n",
    "           '哈利波特与凤凰社','哈利波特与混血王子','哈利波特与死亡圣器']\n",
    "for file_name in file_names:\n",
    "    chapter_no=1\n",
    "    output_name = './dataset/哈利波特/output/句子长度/'+file_name+' 句子长度.xlsx'\n",
    "    file_path = './dataset/哈利波特/'+file_name+'(人文版).txt'\n",
    "    text = open(file_path, 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "    sentence_len=sentence_length(text)\n",
    "    results_df=pd.DataFrame(columns = ['句子','长度']) #为了方便存储，我把dict转成了dataframe格式，最后存放在excel表格里\n",
    "    results_df['句子']=sentence_len.keys()\n",
    "    results_df['长度']=sentence_len.values()\n",
    "    results_df.to_excel(output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate flags for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate flags in each sentence\n",
    "def flag_counting(each_sentence):\n",
    "    # words_flags is the results of pseg.cut()\n",
    "    words_flags = pseg.cut(each_sentence)\n",
    "    #word presents each word, while flag means the property of the word\n",
    "    flag_counting=dict()\n",
    "    for word,flag in words_flags:    \n",
    "        if flag not in flag_counting:\n",
    "            flag_counting[flag] = 1\n",
    "        else:\n",
    "            flag_counting[flag] += 1\n",
    "    \n",
    "    return flag_counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tables for the results of the flag_calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_generation(sentence_dict, flag_counting):\n",
    "    df = pd.DataFrame(columns = ['句子'])\n",
    "    df['句子']=sentence_dict\n",
    "    line_num = 0\n",
    "    for line in flag_counting:\n",
    "        #k presents each flag in one sentence.\n",
    "        for k in line.keys():\n",
    "            \n",
    "            if k not in df.columns:\n",
    "                df[k] = 0\n",
    "            df[k][line_num] = line[k]       \n",
    "        line_num +=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the results of flags_calculator and save it into the .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "x\n",
      "n\n",
      "x\n",
      "n\n",
      "v\n",
      "ul\n",
      "x\n",
      "t\n",
      "uj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "a\n",
      "ul\n",
      "x\n",
      "r\n",
      "d\n",
      "v\n",
      "uj\n",
      "n\n",
      "x\n",
      "d\n",
      "nr\n",
      "ul\n",
      "n\n",
      "x\n",
      "nr\n",
      "v\n",
      "ul\n",
      "x\n",
      "n\n",
      "v\n",
      "ul\n",
      "x\n",
      "ns\n",
      "uj\n",
      "n\n",
      "v\n",
      "ul\n",
      "x\n",
      "n\n",
      "i\n",
      "p\n",
      "v\n",
      "x\n",
      "z\n",
      "x\n",
      "z\n",
      "x\n",
      "n\n",
      "f\n",
      "x\n",
      "nr\n",
      "f\n",
      "x\n",
      "v\n",
      "x\n",
      "m\n",
      "n\n",
      "a\n",
      "v\n",
      "uj\n",
      "x\n",
      "v\n",
      "uz\n",
      "x\n",
      "v\n",
      "uz\n",
      "x\n",
      "v\n",
      "m\n",
      "x\n",
      "v\n",
      "n\n",
      "x\n",
      "nz\n",
      "m\n",
      "v\n",
      "x\n",
      "v\n",
      "m\n",
      "x\n",
      "n\n",
      "z\n",
      "x\n",
      "n\n",
      "z\n",
      "uj\n",
      "x\n",
      "n\n",
      "x\n",
      "r\n",
      "v\n",
      "x\n",
      "r\n",
      "v\n",
      "x\n",
      "d\n",
      "v\n",
      "ul\n",
      "n\n",
      "x\n",
      "a\n",
      "uj\n",
      "v\n",
      "n\n",
      "x\n",
      "n\n",
      "uj\n",
      "v\n",
      "x\n",
      "a\n",
      "uj\n",
      "v\n",
      "n\n",
      "x\n",
      "nr\n",
      "v\n",
      "uz\n",
      "n\n",
      "x\n",
      "ul\n",
      "s\n",
      "d\n",
      "a\n",
      "v\n",
      "n\n",
      "x\n",
      "v\n",
      "f\n",
      "i\n",
      "uj\n",
      "n\n",
      "z\n",
      "uz\n",
      "x\n",
      "b\n",
      "uj\n",
      "n\n",
      "i\n",
      "x\n",
      "n\n",
      "v\n",
      "x\n",
      "v\n",
      "n\n",
      "uj\n",
      "x\n",
      "v\n",
      "n\n",
      "uj\n",
      "x\n",
      "v\n",
      "p\n",
      "l\n",
      "x\n",
      "v\n",
      "n\n",
      "x\n",
      "v\n",
      "nz\n",
      "x\n",
      "d\n",
      "v\n",
      "y\n",
      "uj\n",
      "x\n",
      "x\n",
      "i\n",
      "nr\n",
      "a\n",
      "uj\n",
      "x\n",
      "v\n",
      "n\n",
      "uj\n",
      "uz\n",
      "r\n",
      "x\n",
      "n\n",
      "f\n",
      "v\n",
      "q\n",
      "a\n",
      "uj\n",
      "x\n",
      "v\n",
      "uz\n",
      "n\n",
      "x\n",
      "v\n",
      "r\n",
      "uj\n",
      "n\n",
      "x\n",
      "d\n",
      "p\n",
      "nz\n",
      "uj\n",
      "n\n",
      "f\n",
      "v\n",
      "x\n",
      "n\n",
      "d\n",
      "nr\n",
      "p\n",
      "s\n",
      "x\n",
      "b\n",
      "v\n",
      "ul\n",
      "x\n",
      "nr\n",
      "n\n",
      "v\n",
      "a\n",
      "uj\n",
      "x\n",
      "v\n",
      "uj\n",
      "n\n",
      "x\n",
      "p\n",
      "n\n",
      "v\n",
      "uz\n",
      "x\n",
      "i\n",
      "n\n",
      "uj\n",
      "x\n",
      "r\n",
      "d\n",
      "t\n",
      "a\n",
      "uv\n",
      "v\n",
      "uz\n",
      "x\n",
      "n\n",
      "v\n",
      "d\n",
      "a\n",
      "uj\n",
      "x\n",
      "m\n",
      "d\n",
      "x\n",
      "v\n",
      "x\n",
      "v\n",
      "x\n",
      "v\n",
      "nr\n",
      "x\n",
      "v\n",
      "n\n",
      "x\n",
      "v\n",
      "n\n",
      "x\n",
      "ad\n",
      "uv\n",
      "v\n",
      "uz\n",
      "x\n",
      "n\n",
      "f\n",
      "a\n",
      "v\n",
      "uz\n",
      "m\n",
      "x\n",
      "n\n",
      "d\n",
      "a\n",
      "ud\n",
      "v\n",
      "x\n",
      "n\n",
      "d\n",
      "a\n",
      "ud\n",
      "v\n",
      "r\n",
      "uj\n",
      "x\n",
      "t\n",
      "x\n",
      "v\n",
      "ul\n",
      "x\n",
      "m\n",
      "n\n",
      "uj\n",
      "x\n",
      "v\n",
      "m\n",
      "nr\n",
      "c\n",
      "nz\n",
      "uj\n",
      "n\n",
      "x\n",
      "p\n",
      "s\n",
      "x\n",
      "a\n",
      "s\n",
      "x\n",
      "ns\n",
      "d\n",
      "x\n",
      "v\n",
      "n\n",
      "d\n",
      "uz\n",
      "uj\n",
      "x\n",
      "s\n",
      "v\n",
      "vn\n",
      "uj\n",
      "n\n",
      "x\n",
      "v\n",
      "n\n",
      "x\n",
      "r\n",
      "uj\n",
      "n\n",
      "x\n",
      "z\n",
      "uj\n",
      "p\n",
      "n\n",
      "f\n",
      "nr\n",
      "uz\n",
      "x\n",
      "s\n",
      "n\n",
      "d\n",
      "m\n",
      "ul\n",
      "x\n",
      "s\n",
      "n\n",
      "d\n",
      "m\n",
      "ul\n",
      "x\n",
      "s\n",
      "x\n",
      "n\n",
      "x\n",
      "a\n",
      "b\n",
      "x\n",
      "d\n",
      "v\n",
      "u\n",
      "x\n",
      "m\n",
      "d\n",
      "v\n",
      "ul\n",
      "x\n",
      "a\n",
      "l\n",
      "x\n",
      "v\n",
      "i\n",
      "x\n",
      "r\n",
      "v\n",
      "uj\n",
      "m\n",
      "t\n",
      "x\n",
      "x\n",
      "i\n",
      "d\n",
      "v\n",
      "n\n",
      "x\n",
      "l\n",
      "n\n",
      "x\n",
      "l\n",
      "v\n",
      "x\n",
      "t\n",
      "v\n",
      "d\n",
      "n\n",
      "uj\n",
      "x\n",
      "l\n",
      "d\n",
      "v\n",
      "a\n",
      "uj\n",
      "x\n",
      "r\n",
      "n\n",
      "uz\n",
      "x\n",
      "t\n",
      "v\n",
      "nr\n",
      "x\n",
      "i\n",
      "uj\n",
      "x\n",
      "v\n",
      "uz\n",
      "x\n",
      "v\n",
      "uz\n",
      "x\n",
      "t\n",
      "v\n",
      "a\n",
      "uj\n",
      "x\n",
      "v\n",
      "n\n",
      "a\n",
      "uj\n",
      "c\n",
      "x\n",
      "v\n",
      "uz\n",
      "r\n",
      "f\n",
      "t\n",
      "x\n"
     ]
    }
   ],
   "source": [
    "file_name='春'\n",
    "#output_name =  file_name+' 句子长度.xlsx'\n",
    "file_path = './dataset/课文/'+file_name+'.txt'\n",
    "text = open(file_path, 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "#df = pd.DataFrame(columns = ['句子','词性'])\n",
    "#df = pd.DataFrame(columns = ['句子'])\n",
    "sentence_arr = []\n",
    "labels = []\n",
    "sentence_list= []\n",
    "pseg_list = []\n",
    "line_counting = 0\n",
    "for block in text:\n",
    "    sentences_list =cut_sent(block)\n",
    "    # sentence is each sentence\n",
    "    for sentence in sentences_list:\n",
    "\n",
    "        sentence_list.append(sentence)\n",
    "        flag_result = flag_counting(sentence)\n",
    "\n",
    "        pseg_list.append(flag_result)\n",
    "#df['句子'] = sentence_list\n",
    "flags_result = table_generation(sentence_list, pseg_list)\n",
    "\n",
    "output_name = './dataset/课文/' + file_name + '_flags.txt'\n",
    "file = open(output_name, 'w')\n",
    "for column in flags_result.columns:\n",
    "    #print(str(list(flags_result[column])))\n",
    "    file.write(str(list(flags_result[column])))   \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['句子', 'n', 'x', 'v', 'ul', 't', 'uj', 'a', 'r', 'd', 'nr', 'ns', 'i',\n",
       "       'p', 'z', 'f', 'm', 'uz', 'nz', 's', 'b', 'l', 'y', 'q', 'uv', 'ad',\n",
       "       'ud', 'c', 'vn', 'u'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
