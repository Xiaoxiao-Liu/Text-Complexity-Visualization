{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  3.  0.  5.  4.  1.  1.  0.  1.  1.  1.  0. 13.  1.  1.  0.  0.  0.\n",
      "  1.  1.  1.  0.  5.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.\n",
      "  1.  0.  0.  0.  2.  0.  1.  0.  1.  2.  0.  0.  0.  2.  1.  8.  0.  1.\n",
      "  0.  1.  3.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  2.  2.  0.  0.  1.\n",
      "  2.  0.  0.  2.  0.  0.  0.  0.  0.  2.  4.  1.  1.  3.  0.  0.  1.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  8.  1.  5.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  3.  1.  1.  2.  3.  1.  0.  0.  1.  1.\n",
      "  0.  0.  1.  0.  1.  1.  0.  3.  0.  2.  1.  0.  0.  1.  0.  0.  0.  0.\n",
      "  1.  1.  0.  0.  3.  1.  0.  0.  1.  0.  1.  1.  0. 22.  0.  1.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  3.  1.  3. 10.  3.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  1.  1.  1.  0.  1.  3.  1.  1.  0.  0.  0.  0.  1.  1.  3.  0.\n",
      "  0.  0.  0.  1.  0.  1.  1.  0.  0.  3.  0.  1.  0.  2.  1.  2.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  1.  0.  0.  2.  1. 11.  0.  0.  0.  0. 30.  0.\n",
      "  1.  1.  2.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  1.  1.  9.  0.  0.  0.  1.  0.  0.  0.  1.  1.  3.  3.  0.  0.  0.\n",
      "  0.  0.  1.  0.  1.  0.  0.  0.  0.  2.  1.  2.  2.  2.  1.  0.  1.  2.\n",
      "  0.  1.  1.  1.  0.  2.  1.  0.  0.  0.  0.  5.  0.  0.  0.  0.  0.  0.\n",
      "  3.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  3.  0. 16.  0.  0.  0.  1.\n",
      "  9.  2.  0.  1. 12.  0.  2.  0.  1.  0.  3.  5.  1.  0.  2.  1.  6.  1.\n",
      "  0.  0.  2.  0.  0.  0.  1.  1. 13.  1.  0.  2.  2.  0.  1.  0.  1.  0.\n",
      "  0.  2.  0.  0.  0.  1.  2.  4.  1.  1.  0.  3.  1.  0.  2.  0.  0.  1.\n",
      "  0.  0.  1.  1.  0.  2.  0.  0.  4.  2.  0.  0.  6.  0.  1.  0.  1.  0.\n",
      "  0.  0.  1.  0.  0.  2.  2.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 1. 19.  1.  0.  2.  0.  0.  2.  0.  0.  0.  1. 20.  0.  0.  1.  3.  1.\n",
      "  0.  2.  1. 10.  5.  3.  1.  6.  1.  1.  0.  1.  0.  0.  1.  1.  2.  3.\n",
      "  0. 13.  1.  1.  1.  2.  0.  1.  0.  3.  1.  2.  1.  3.  1. 27.  1.  1.\n",
      "  1.  0. 17.  1.  0.  1.  1.  2.  0.  1.  0.  2.  1.  0.  0.  1.  1.  1.\n",
      "  2.  4.  1.  1.  1.  1.  2.  1.  1.  0.  4.  1.  0.  5.  2.  1.  0.  0.\n",
      "  1.  0.  2.  2.  2.  1.  1.  0.  3.  1.  1.  1.  2.  0.  4.  1.  1.  1.\n",
      "  1.  1.  1.  2. 10.  1.  0.  2.  2.  0.  0.  3.  0.  0.  1.  1.  0.  0.\n",
      "  3.  1.  0.  3.  0.  0.  1.  1.  1.  6.  0.  2.  1.  0.  1.  2.  1.  2.\n",
      "  0.  1.  1.  1. 19.  0.  4.  1.  0.  1.  0.  1.  1. 60.  1.  5.  3.  0.\n",
      "  2.  0.  2.  5.  3.  1.  0.  0.  0.  0.  0.  4.  0.  5.  1.  1.  0.  2.\n",
      "  1.  1.  2.  0.  0.  1.  0.  3.  0.  1.  2.  1.  1.  2.  0.  1.  0.  3.\n",
      "  2.  1.  1.  0.  2.  0.  2.  1.  1.  3.  1.  1.  1.  2. 10.  2.  1.  3.\n",
      "  2.  0.  1. 16.  0.  1.  1.  1.  1.  0.  1. 26.  4.  1.  1.  1. 62.  1.\n",
      "  0.  0.  3.  3.  0.  2.  1.  1.  0.  2.  2.  1.  1.  1.  2.  2.  1.  1.\n",
      "  1.  1.  0.  0.  1.  2.  1.  1.  1.  1.  1.  1.  0.  7.  0.  1. 25.  1.\n",
      "  1.  1.  0.  1.  0.  1. 10.  1.  1.  0.  0.  0.  2.  2.  0.  3.  1.  0.\n",
      "  1.  0.  0.  0. 15.  0.  0.  1.  1.  1.  5.  0.  4.  1.  1.  1.  1.  1.\n",
      "  0.  2.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  1.  5.  2.  2.  1.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  1.  0.  2.  0.  2.  0.  1.  0.  0.  0.  0.\n",
      "  1.  1.  1.  1.  1.  1.  3.  0. 20.  0.  1.  0.  6.  3.  4.  1.  1.  1.\n",
      "  1.  3.  1.  3.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.\n",
      "  1.  1.  0.  0.  1. 19.  3.  4.  8.  0.  1.  1.  0.  1.  0.  1.  0.  1.\n",
      "  2.  1.  0.  2.  2.  0.  0.  1.  1.  1.  2.  2.  1.  1.  0.  2.]\n",
      "0.7119768768610493\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import jieba\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def get_word_vector(s1,s2):\n",
    "    \"\"\"\n",
    "    :param s1: 句子1\n",
    "    :param s2: 句子2\n",
    "    :return: 返回句子的余弦相似度\n",
    "    \"\"\"\n",
    "    # 分词\n",
    "    cut1 = jieba.cut(s1)\n",
    "    cut2 = jieba.cut(s2)\n",
    "    list_word1 = (','.join(cut1)).split(',')\n",
    "    list_word2 = (','.join(cut2)).split(',')\n",
    "\n",
    "    # 列出所有的词,取并集\n",
    "    key_word = list(set(list_word1 + list_word2))\n",
    "    # 给定形状和类型的用0填充的矩阵存储向量\n",
    "    word_vector1 = np.zeros(len(key_word))\n",
    "    word_vector2 = np.zeros(len(key_word))\n",
    "\n",
    "    # 计算词频\n",
    "    # 依次确定向量的每个位置的值\n",
    "    for i in range(len(key_word)):\n",
    "        # 遍历key_word中每个词在句子中的出现次数\n",
    "        for j in range(len(list_word1)):\n",
    "            if key_word[i] == list_word1[j]:\n",
    "                word_vector1[i] += 1\n",
    "        for k in range(len(list_word2)):\n",
    "            if key_word[i] == list_word2[k]:\n",
    "                word_vector2[i] += 1\n",
    "\n",
    "    # 输出向量\n",
    "    print(word_vector1)\n",
    "    print(word_vector2)\n",
    "    return word_vector1, word_vector2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cos_dist(vec1,vec2):\n",
    "    \"\"\"\n",
    "    :param vec1: 向量1\n",
    "    :param vec2: 向量2\n",
    "    :return: 返回两个向量的余弦相似度\n",
    "    \"\"\"\n",
    "    dist1=float(np.dot(vec1,vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2)))\n",
    "    return dist1\n",
    "\n",
    "def filter_html(html):\n",
    "    \"\"\"\n",
    "    :param html: html\n",
    "    :return: 返回去掉html的纯净文本\n",
    "    \"\"\"\n",
    "    dr = re.compile(r'<[^>]+>',re.S)\n",
    "    dd = dr.sub('',html).strip()\n",
    "    return dd\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filex = open(\"./dataset/数据/马来西亚寓言故事.txt\", encoding = 'utf-8')\n",
    "    s1 = filex.read()\n",
    "    filey = open(\"./dataset/数据/马亚西亚寓言故事.txt\", encoding = 'utf-8')\n",
    "    s2 = filey.read()\n",
    "    #s1=\"很高兴见到你\"\n",
    "    #s2=\"我也很高兴见到你\"\n",
    "    vec1,vec2=get_word_vector(s1,s2)\n",
    "    dist1=cos_dist(vec1,vec2)\n",
    "    print(dist1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "filex = open(\"./dataset/数据/马来西亚寓言故事.txt\", encoding = 'utf-8')\n",
    "a = filex.read()\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
