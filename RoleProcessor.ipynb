{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import codecs\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate words for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/89/qp8kb90s49z7xcdskq2c0qlm0000gn/T/jieba.cache\n",
      "Loading model cost 0.688 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "\n",
    "# 创建停用词list\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "# 对句子进行分词\n",
    "def seg_sentence(sentence):\n",
    "    sentence_seged = jieba.cut(sentence.strip())\n",
    "    stopwords = stopwordslist('stoped.txt')  # 这里加载停用词的路径\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords:\n",
    "            if word != '\\t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the frequency of roles in certain length text\n",
    "def calculate_roles(inputs,roles_df):\n",
    "    roles_dict=dict()\n",
    "    for line in inputs:\n",
    "        #print(line)\n",
    "        line_seg = seg_sentence(line)\n",
    "        words_list=list(line_seg.split(' '))\n",
    "        #print(words_list)\n",
    "        for role in roles_df['character']:\n",
    "            #print(role)\n",
    "            if role in words_list:\n",
    "                if role not in roles_dict:\n",
    "                    roles_dict[role]=1\n",
    "                else:\n",
    "                    roles_dict[role]+=1\n",
    "                #print(role)\n",
    "    return roles_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seperate chapters and save all chapters into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_chapters(text,chapter_df):\n",
    "    one_chapter=list() #used to save all lines in single chapter\n",
    "    all_chapters=list() # used to save all chapters into one list\n",
    "    for line in text:\n",
    "        for chpater_no in chapter_df['chapters']:\n",
    "            if chpater_no in line:\n",
    "                all_chapters.append(one_chapter)\n",
    "                one_chapter=list()\n",
    "        one_chapter.append(line)\n",
    "        #print(one_chapter)\n",
    "    return all_chapters\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate role frequency in each chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read texts\n",
    "# Read character file\n",
    "#text = open('哈利波特与密室(人文版).txt', 'r',encoding=\"gbk\") #加载要处理的文件的路径\n",
    "roles_df=pd.read_excel('character.xlsx',names=['character'],index=[0])\n",
    "roles_df.head()\n",
    "# Read chapter file\n",
    "chapter_df=pd.read_excel('chapters.xlsx',index=[0])\n",
    "#chapter_df.head()\n",
    "# Save the book names in a list\n",
    "file_names=['哈利波特与魔法石','哈利波特与密室','哈利波特与阿兹卡班的囚徒','哈利波特与火焰杯',\n",
    "           '哈利波特与凤凰社','哈利波特与混血王子','哈利波特与死亡圣器']\n",
    "\n",
    "for file_name in file_names:\n",
    "    chapter_no=1\n",
    "    file_path = './dataset/哈利波特/'+file_name+'(人文版).txt'\n",
    "    text = open(file_path, 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "    #Seperate chapters for the text\n",
    "    chapters_list=sep_chapters(text,chapter_df)\n",
    "    #calculate role numbers for each chapter and save it into a .xlsx file\n",
    "    for chapter in chapters_list: \n",
    "        output_name = './dataset/哈利波特/output/角色统计/'+file_name+' 第'+str(chapter_no)+'章 角色统计.xlsx'\n",
    "        #print(output_name)\n",
    "        chapter_freq=calculate_roles(chapter,roles_df)\n",
    "        result_df=pd.DataFrame(columns = ['角色','出现次数'])\n",
    "        result_df['角色'] = chapter_freq.keys()\n",
    "        result_df['出现次数'] = chapter_freq.values()\n",
    "        result_df.sort_values(by='出现次数',axis=0,ascending=False, inplace=True)\n",
    "        result_df.to_excel(output_name)\n",
    "        chapter_no+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate role frequencies in each book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read texts\n",
    "# Read character file\n",
    "#text = open('哈利波特与密室(人文版).txt', 'r',encoding=\"gbk\") #加载要处理的文件的路径\n",
    "roles_df=pd.read_excel('character.xlsx',names=['character'],index=[0])\n",
    "roles_df.head()\n",
    "# Read chapter file\n",
    "chapter_df=pd.read_excel('chapters.xlsx',index=[0])\n",
    "#chapter_df.head()\n",
    "# Save the book names in a list\n",
    "file_names=['哈利波特与魔法石','哈利波特与密室','哈利波特与阿兹卡班的囚徒','哈利波特与火焰杯',\n",
    "           '哈利波特与凤凰社','哈利波特与混血王子','哈利波特与死亡圣器']\n",
    "\n",
    "for file_name in file_names:\n",
    "    chapter_no=1\n",
    "    file_path = './dataset/哈利波特/'+file_name+'(人文版).txt'\n",
    "    text = open(file_path, 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "    output_name = './dataset/哈利波特/output/角色统计/'+file_name+' 角色统计.xlsx'\n",
    "    #print(output_name)\n",
    "    result_df=pd.DataFrame(columns = ['角色','出现次数'])\n",
    "    #Seperate chapters for the text\n",
    "    chapters_list=sep_chapters(text,chapter_df)\n",
    "    #calculate role numbers for each chapter and save it into a .xlsx file\n",
    "    chapter_freq=calculate_roles(text,roles_df)\n",
    "    #print(chapter_freq)\n",
    "    result_df['角色'] = chapter_freq.keys()\n",
    "    result_df['出现次数'] = chapter_freq.values()\n",
    "    result_df.sort_values(by='出现次数',axis=0,ascending=False, inplace=True)\n",
    "    result_df.to_excel(output_name)\n",
    "    chapter_no+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data of relationships between characters/roles in the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genereate text of each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate single line data\n",
    "def line_generating(text):\n",
    "    word_counting = 1 # line one\n",
    "    words_in_line = 30 #There are 30 words in a line in the book\n",
    "    one_line = '' # save the word in a line into a string\n",
    "    result_lines = '' # save all lines into one list\n",
    "    for blocks in text:\n",
    "        #print(blocks)\n",
    "        for word in blocks:\n",
    "            if word == '\\n':\n",
    "                #lines.append(one_line)\n",
    "                word_counting=0\n",
    "                one_line = ''\n",
    "            elif word_counting <= 30:\n",
    "                #print(word)\n",
    "                one_line = one_line+word\n",
    "            else:\n",
    "                result_lines = result_lines + '\\n' +one_line\n",
    "                #print(one_line)\n",
    "                word_counting=0\n",
    "                one_line = ''\n",
    "            #print(one_line)\n",
    "            word_counting +=1\n",
    "    return result_lines\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate lines in each page and save them all in a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_generating(text_lines):\n",
    "    #因为每35行是一页，所以我们把每一页的第一行保存起来，\n",
    "    #就像我们分章节时，我们把‘第一章’，‘第二章‘这样的mark保存起来，这样程序遍历文本时，遇到每页第一行就保存下来\n",
    "    line_counting = 1 #line one\n",
    "    lines_in_page = 36 #There are 35 lines in a page of the book\n",
    "    page_mark = []\n",
    "    for line in text_lines.split('\\n'):   \n",
    "        if line_counting >= lines_in_page:\n",
    "            page_mark.append(line)\n",
    "            line_counting =1\n",
    "        line_counting += 1\n",
    "    page_mark_df=pd.DataFrame(columns = ['chapters'])\n",
    "    page_mark_df['chapters']=page_mark\n",
    "    return page_mark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the page mark for each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_no=1\n",
    "file_path = './dataset/哈利波特/哈利波特与死亡圣器(人文版).txt'\n",
    "text = open(file_path, 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "result_lines = line_generating(text)\n",
    "result_mark = page_generating(result_lines)\n",
    "#text.close()\n",
    "#page_mark_df=pd.DataFrame(columns = ['chapters'])\n",
    "#page_mark_df['chapters']=page_mark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“星期六……傍晚。”伏地魔重复了一句。他的红眼睛死死</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“这样更好，”伏地魔说，“他只好在露天转移。要抓住他</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>多年来，他们不是一直口口声声地宣称希望我复出，希望我东山再起</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>。那女人旋转着面对炉火时，用沙哑而恐惧的声音说：“西弗勒斯！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>和波特臭大粪的淡淡字样；接着他又掏出一个破旧开裂的窥镜和一个</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         chapters\n",
       "0      “星期六……傍晚。”伏地魔重复了一句。他的红眼睛死死\n",
       "1      “这样更好，”伏地魔说，“他只好在露天转移。要抓住他\n",
       "2  多年来，他们不是一直口口声声地宣称希望我复出，希望我东山再起\n",
       "3  。那女人旋转着面对炉火时，用沙哑而恐惧的声音说：“西弗勒斯！\n",
       "4  和波特臭大粪的淡淡字样；接着他又掏出一个破旧开裂的窥镜和一个"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_mark.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate text in pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './dataset/哈利波特/哈利波特与死亡圣器(人文版).txt'\n",
    "text = open(file_path, 'r',encoding=\"utf-8\") #加载要处理的文件的路径\n",
    "pages_list=sep_chapters(text,result_mark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get roles in each pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles_df=pd.read_excel('character.xlsx',names=['character'],index=[0])\n",
    "roles_df.head()\n",
    "page_roles = []\n",
    "#calculate role numbers in each page and save them all in a list for now\n",
    "for chapter in pages_list: \n",
    "    #output_name = './dataset/哈利波特/output/角色统计/'+file_name+' 第'+str(chapter_no)+'章 角色统计.xlsx'\n",
    "    #print(output_name)\n",
    "    chapter_freq=calculate_roles(chapter,roles_df)\n",
    "    page_roles.append(list(chapter_freq.keys()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get two-role combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_role_combinations(page_roles):\n",
    "    role_collections = [] # A container for all two-role combinations\n",
    "    for roles in page_roles:    \n",
    "        j= len(roles)\n",
    "        while j>1:\n",
    "            j-=1\n",
    "            i=j\n",
    "            role_com = set()        \n",
    "            while i>0:\n",
    "                i-=1\n",
    "                #print(roles[i])\n",
    "                role_com.add(roles[j])\n",
    "                role_com.add(roles[i])\n",
    "                role_collections.append(tuple(role_com))\n",
    "                #print(role_com)\n",
    "                role_com = set()\n",
    "    result = Counter(role_collections)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_counter=get_role_combinations(page_roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate the results into formatted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('哈利波特与死亡圣器人物关系.txt', 'w')\n",
    "file.write('[')\n",
    "for relations in combination_counter.keys():\n",
    "    #print(k)\n",
    "    file.write('[')\n",
    "    for person in relations:\n",
    "        #print(i)\n",
    "        file.write(\"'\"+person+\"',\")\n",
    "        #file.write(',')\n",
    "    #print(c[k])\n",
    "    file.write(str(combination_counter[relations])+'],\\n')\n",
    "    \n",
    "file.write(']')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
